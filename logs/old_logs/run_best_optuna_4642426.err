#######################################################################################
### conda added to PATH. Use 'source activate' rather than 'conda activate'.        ###
### Do not run 'conda init' if prompted.                                            ###
### 'conda init' will modify your shell outside of the `module` environment         ###
#######################################################################################
[I 2025-10-20 18:22:09,745] A new study created in RDB with name: rain_diffusion_1760977329
[I 2025-10-20 20:12:34,345] Trial 0 finished with value: 0.016133240785781818 and parameters: {'model_channels': 256, 'num_blocks': 3, 'dropout': 0.03130174564669214, 'downsample_type': 'residual', 'channel_mult': '1224', 'attn_config': 'none', 'timesteps': 1000, 'beta_schedule': 'linear', 'loss': 'mse', 'optimizer': 'Adam', 'scheduler': 'ExponentialLR', 'lr': 1.3180011342814892e-05}. Best is trial 0 with value: 0.016133240785781818.
slurmstepd-csl14c251: error: _handle_stat_jobacct: Took usec=-1066425, which is more than MessageTimeout (10s). The result won't be delivered
[I 2025-10-20 20:55:13,901] Trial 1 finished with value: 0.08283767937363475 and parameters: {'model_channels': 256, 'num_blocks': 2, 'dropout': 0.004206680211091096, 'downsample_type': 'standard', 'channel_mult': '1124', 'attn_config': 'last_two', 'timesteps': 250, 'beta_schedule': 'exponential', 'loss': 'huber', 'optimizer': 'AdamW', 'scheduler': 'WarmupCosine', 'lr': 0.00043386918629694757}. Best is trial 0 with value: 0.016133240785781818.
[I 2025-10-20 22:31:32,052] Trial 2 finished with value: 0.023404714264165995 and parameters: {'model_channels': 64, 'num_blocks': 2, 'dropout': 0.04334160803783891, 'downsample_type': 'residual', 'channel_mult': '124', 'attn_config': 'none', 'timesteps': 500, 'beta_schedule': 'linear', 'loss': 'l1', 'optimizer': 'AdamW', 'scheduler': 'ExponentialLR', 'lr': 6.44902600899981e-05}. Best is trial 0 with value: 0.016133240785781818.
[I 2025-10-21 00:59:25,310] Trial 3 finished with value: 0.058899067886147766 and parameters: {'model_channels': 128, 'num_blocks': 3, 'dropout': 0.14212395339258366, 'downsample_type': 'residual', 'channel_mult': '1124', 'attn_config': 'none', 'timesteps': 500, 'beta_schedule': 'exponential', 'loss': 'l1', 'optimizer': 'Adam', 'scheduler': 'ExponentialLR', 'lr': 0.00013376002128927814}. Best is trial 0 with value: 0.016133240785781818.
[I 2025-10-21 03:38:23,023] Trial 4 finished with value: 0.07496453245775071 and parameters: {'model_channels': 128, 'num_blocks': 3, 'dropout': 0.20728423340500357, 'downsample_type': 'standard', 'channel_mult': '1224', 'attn_config': 'last', 'timesteps': 250, 'beta_schedule': 'exponential', 'loss': 'mse', 'optimizer': 'AdamW', 'scheduler': 'WarmupCosine', 'lr': 7.760678189614634e-05}. Best is trial 0 with value: 0.016133240785781818.
[I 2025-10-21 05:40:45,226] Trial 5 finished with value: 0.037675072022948446 and parameters: {'model_channels': 128, 'num_blocks': 1, 'dropout': 0.2509974562154843, 'downsample_type': 'standard', 'channel_mult': '1248', 'attn_config': 'last_two', 'timesteps': 500, 'beta_schedule': 'quadratic', 'loss': 'huber', 'optimizer': 'AdamW', 'scheduler': 'ExponentialLR', 'lr': 2.9221891696657315e-05}. Best is trial 0 with value: 0.016133240785781818.
[I 2025-10-21 06:10:46,041] Trial 6 pruned. 
[I 2025-10-21 08:08:20,845] Trial 7 finished with value: 0.027700080329949268 and parameters: {'model_channels': 128, 'num_blocks': 1, 'dropout': 0.2974213720379809, 'downsample_type': 'standard', 'channel_mult': '1248', 'attn_config': 'last', 'timesteps': 1000, 'beta_schedule': 'quadratic', 'loss': 'l1', 'optimizer': 'AdamW', 'scheduler': 'ExponentialLR', 'lr': 6.32603742312376e-05}. Best is trial 0 with value: 0.016133240785781818.
[I 2025-10-21 08:19:27,191] Trial 8 pruned. 
[I 2025-10-21 09:12:07,042] Trial 9 finished with value: 0.0317821316654133 and parameters: {'model_channels': 64, 'num_blocks': 1, 'dropout': 0.011435290367887208, 'downsample_type': 'standard', 'channel_mult': '1248', 'attn_config': 'none', 'timesteps': 500, 'beta_schedule': 'cosine', 'loss': 'huber', 'optimizer': 'AdamW', 'scheduler': 'WarmupCosine', 'lr': 0.000774026395299194}. Best is trial 0 with value: 0.016133240785781818.
[I 2025-10-21 11:22:58,894] Trial 10 finished with value: 0.016039213343826582 and parameters: {'model_channels': 256, 'num_blocks': 3, 'dropout': 0.10410844277431183, 'downsample_type': 'residual', 'channel_mult': '1224', 'attn_config': 'none', 'timesteps': 1000, 'beta_schedule': 'linear', 'loss': 'mse', 'optimizer': 'Adam', 'scheduler': 'ExponentialLR', 'lr': 1.3137050962202345e-05}. Best is trial 10 with value: 0.016039213343826582.
[I 2025-10-21 13:18:03,206] Trial 11 finished with value: 0.01611017192540578 and parameters: {'model_channels': 256, 'num_blocks': 3, 'dropout': 0.0845216260270969, 'downsample_type': 'residual', 'channel_mult': '1224', 'attn_config': 'none', 'timesteps': 1000, 'beta_schedule': 'linear', 'loss': 'mse', 'optimizer': 'Adam', 'scheduler': 'ExponentialLR', 'lr': 1.1956495422428271e-05}. Best is trial 10 with value: 0.016039213343826582.
[I 2025-10-21 14:39:41,980] Trial 12 finished with value: 0.01659685134015324 and parameters: {'model_channels': 256, 'num_blocks': 3, 'dropout': 0.10587388556910138, 'downsample_type': 'residual', 'channel_mult': '1224', 'attn_config': 'none', 'timesteps': 1000, 'beta_schedule': 'linear', 'loss': 'mse', 'optimizer': 'Adam', 'scheduler': 'ExponentialLR', 'lr': 1.1228379294224482e-05}. Best is trial 10 with value: 0.016039213343826582.
[I 2025-10-21 16:13:27,709] Trial 13 finished with value: 0.01644266770344604 and parameters: {'model_channels': 256, 'num_blocks': 2, 'dropout': 0.09105552307540485, 'downsample_type': 'residual', 'channel_mult': '1224', 'attn_config': 'none', 'timesteps': 1000, 'beta_schedule': 'linear', 'loss': 'mse', 'optimizer': 'Adam', 'scheduler': 'ExponentialLR', 'lr': 2.2214221858553902e-05}. Best is trial 10 with value: 0.016039213343826582.
[I 2025-10-21 17:33:31,811] Trial 14 finished with value: 0.015949662925411043 and parameters: {'model_channels': 256, 'num_blocks': 3, 'dropout': 0.08545693212770945, 'downsample_type': 'residual', 'channel_mult': '124', 'attn_config': 'none', 'timesteps': 1000, 'beta_schedule': 'linear', 'loss': 'mse', 'optimizer': 'Adam', 'scheduler': 'ExponentialLR', 'lr': 2.1803841579667504e-05}. Best is trial 14 with value: 0.015949662925411043.
[I 2025-10-21 17:46:55,058] Trial 15 pruned. 
[I 2025-10-21 17:56:24,245] Trial 16 pruned. 
[I 2025-10-21 19:49:24,942] Trial 17 finished with value: 0.015565835863487571 and parameters: {'model_channels': 256, 'num_blocks': 2, 'dropout': 0.06538756982059785, 'downsample_type': 'residual', 'channel_mult': '124', 'attn_config': 'none', 'timesteps': 1000, 'beta_schedule': 'linear', 'loss': 'mse', 'optimizer': 'Adam', 'scheduler': 'ExponentialLR', 'lr': 3.9164412080817596e-05}. Best is trial 17 with value: 0.015565835863487571.
[I 2025-10-21 20:57:44,075] Trial 18 pruned. 
[I 2025-10-21 21:09:47,362] Trial 19 pruned. 
[I 2025-10-21 21:38:39,470] Trial 20 pruned. 
[I 2025-10-21 22:18:38,032] Trial 21 pruned. 
[I 2025-10-21 23:25:20,266] Trial 22 finished with value: 0.01689334683360653 and parameters: {'model_channels': 256, 'num_blocks': 3, 'dropout': 0.070755491458628, 'downsample_type': 'residual', 'channel_mult': '124', 'attn_config': 'none', 'timesteps': 1000, 'beta_schedule': 'linear', 'loss': 'mse', 'optimizer': 'Adam', 'scheduler': 'ExponentialLR', 'lr': 1.4607761237328855e-05}. Best is trial 17 with value: 0.015565835863487571.
